{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qTXsrSn36f1"
      },
      "source": [
        "# Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EfjDQXf36f2"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Ridge,SGDRegressor,HuberRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-B2Gpiol36f3"
      },
      "source": [
        "### Load datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vbfrete36f3"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load the Boston Housing dataset\n",
        "california_housing = fetch_california_housing()\n",
        "X, y = california_housing.data, california_housing.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ordinary Least Squares (OLS) Regression\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHUQ9Gcb36f3"
      },
      "source": [
        "### Linear regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FVVyxR936f4"
      },
      "outputs": [],
      "source": [
        "ols_model = LinearRegression()\n",
        "ols_model.fit(X_train, y_train)\n",
        "ols_pred = ols_model.predict(X_test)\n",
        "ols_mse = mean_squared_error(y_test, ols_pred)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GT8r0cmv36f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbfc5368-bbb9-4bda-9f9e-9bacd743beeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OLS Mean Squared Error: 0.5558915986952422\n",
            "Ridge Mean Squared Error: 0.5558034669932196\n"
          ]
        }
      ],
      "source": [
        "# Ridge Regression\n",
        "ridge_model = Ridge(alpha=1.0)\n",
        "ridge_model.fit(X_train, y_train)\n",
        "ridge_pred = ridge_model.predict(X_test)\n",
        "ridge_mse = mean_squared_error(y_test, ridge_pred)\n",
        "\n",
        "print(\"OLS Mean Squared Error:\", ols_mse)\n",
        "print(\"Ridge Mean Squared Error:\", ridge_mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3oFUX4V36f4"
      },
      "outputs": [],
      "source": [
        "huber_regressor = HuberRegressor(epsilon=1.35)  # Epsilon is the threshold parameter\n",
        "huber_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing set\n",
        "y_pred = huber_regressor.predict(X_test)\n",
        "\n",
        "# Evaluate the model using Mean Squared Error (MSE) and Mean Absolute Error (MAE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "print(\"Huber Regressor Mean Squared Error (MSE):\", mse)\n",
        "print(\"Huber Regressor Mean Absolute Error (MAE):\", mae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDpEwmD036f4"
      },
      "source": [
        "### SGD Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9izXrIg-36f4",
        "outputId": "0e3021fc-da08-4357-c30f-b09c7e451b35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('squared_epsilon_insensitive', 'l1', 'constant', 2.123072719133613e+30, 1338361073750148.5)]\n",
            "Loss function: squared_epsilon_insensitive\n",
            "Penalty term: l1\n",
            "Learning rate schedule: constant\n",
            "Mean Squared Error (MSE): 2.123072719133613e+30\n",
            "Mean Absolute Error (MAE): 1338361073750148.5\n"
          ]
        }
      ],
      "source": [
        "'''Let's play around with different loss functions and different regularizers and see how the model can react.\n",
        "Don't worry you cannot break the california housing dataset'''\n",
        "\n",
        "# Initialize SGDRegressor with different parameters\n",
        "# Below are some common parameters you can tune:\n",
        "\n",
        "# Loss function: 'squared_loss' (default), 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'\n",
        "# 'squared_loss': Ordinary least squares (OLS) loss\n",
        "# 'huber': Huber loss, a combination of MSE and MAE that is less sensitive to outliers\n",
        "# 'epsilon_insensitive': Linear Support Vector Regression (SVR)\n",
        "# 'squared_epsilon_insensitive': SVR with squared hinge loss\n",
        "loss_functions = ['squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive']\n",
        "\n",
        "# Penalty term:  'l2', 'l1', or 'elasticnet'\n",
        "penalty_terms = ['elasticnet', 'l1', 'l2']\n",
        "# Learning rate schedule: 'constant' (default), 'optimal', 'invscaling', 'adaptive'\n",
        "# 'constant': a constant learning rate given by the 'eta0' parameter\n",
        "# 'optimal': an optimal learning rate is chosen via theoretical analysis\n",
        "# 'invscaling': gradually decreases the learning rate 'eta0' at each time step 't' using an inverse scaling exponent of 'power_t'\n",
        "# 'adaptive': the learning rate is kept constant as long as the training loss decreases, then it is decreased by 'eta0' to improve convergence\n",
        "learning_rate_schedules = ['constant', 'optimal', 'invscaling', 'adaptive']\n",
        "penalty = penalty_terms[1]\n",
        "loss = loss_functions[3]\n",
        "lr_schedule = learning_rate_schedules[0]\n",
        "# Initialize lists to store results\n",
        "\n",
        "            # Initialize SGDRegressor with current parameters\n",
        "sgd_regressor = SGDRegressor(loss=loss, penalty=penalty, learning_rate=lr_schedule, random_state=42,max_iter = 10)\n",
        "\n",
        "            # Fit the model on the training data\n",
        "sgd_regressor.fit(X_train, y_train)\n",
        "\n",
        "            # Make predictions on the test set\n",
        "y_pred = sgd_regressor.predict(X_test)\n",
        "\n",
        "            # Calculate evaluation metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        " # Store results\n",
        "result = []\n",
        "result.append((loss, penalty, lr_schedule, mse, mae))\n",
        "\n",
        "# Print the results\n",
        "print(result)\n",
        "print(\"Loss function:\", result[0][0])\n",
        "print(\"Penalty term:\", result[0][1])\n",
        "print(\"Learning rate schedule:\", result[0][2])\n",
        "print(\"Mean Squared Error (MSE):\", result[0][3])\n",
        "print(\"Mean Absolute Error (MAE):\", result[0][4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnbypL-L36f4"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsNvmQo936f4"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDEXvw7I36f4"
      },
      "source": [
        "### Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiiS3yQh36f4",
        "outputId": "5cf9e259-5aea-4dad-e86e-4bccbe785fe0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.956140350877193\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_breast_cancer()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Logistic Regression\n",
        "logistic_model = LogisticRegression(max_iter=100000)\n",
        "logistic_model.fit(X_train, y_train)\n",
        "logistic_pred = logistic_model.predict(X_test)\n",
        "logistic_accuracy = accuracy_score(y_test, logistic_pred)\n",
        "\n",
        "print(\"Logistic Regression Accuracy:\", logistic_accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osjjmdCt36f5"
      },
      "source": [
        "### Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA4je7MH36f5",
        "outputId": "28dafe19-0979-4788-842d-37f2cdb6e329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "kernels = ['linear','poly','rbf','sigmoid']\n",
        "kernel = kernels[2]\n",
        "C_values = [0.1, 1, 10]\n",
        "svm_classifier = SVC(kernel=kernel,C=C_values[0],max_iter=100)  # You can adjust kernel and other parameters\n",
        "\n",
        "# Train the classifier\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing set\n",
        "y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsyyQuRi36f5",
        "outputId": "78b3695d-f6bd-4a5e-e137-3ad8f604f36e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kernel: rbf\n",
            "Accuracy: 0.9385964912280702\n",
            "Precision: 0.9441070625281152\n",
            "Recall: 0.9385964912280702\n",
            "F1-score: 0.937318446911604\n"
          ]
        }
      ],
      "source": [
        "print(f\"Kernel: {kernel}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-score: {f1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "565otQaf36f5"
      },
      "source": [
        "### Train Vs Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoqPRZoN36f5",
        "outputId": "f49f6161-9294-4e10-b13c-d70292a2b84d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  87.6923076923077 %\n",
            "testing accuracy  0.9385964912280702 %\n"
          ]
        }
      ],
      "source": [
        "training_accuracy = svm_classifier.score(X_train,y_train)\n",
        "print(\"Training Accuracy: \",training_accuracy*100,\"%\")\n",
        "testing_accuracy = svm_classifier.score(X_test, y_test)\n",
        "print(\"testing accuracy \",testing_accuracy,\"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hp8IC7Gz36f5"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}